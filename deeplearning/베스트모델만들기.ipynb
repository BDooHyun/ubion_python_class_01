{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 12.28052, saving model to ./model\\01-12.2805.hdf5\n",
      "\n",
      "Epoch 2: val_loss improved from 12.28052 to 8.70951, saving model to ./model\\02-8.7095.hdf5\n",
      "\n",
      "Epoch 3: val_loss improved from 8.70951 to 6.36116, saving model to ./model\\03-6.3612.hdf5\n",
      "\n",
      "Epoch 4: val_loss improved from 6.36116 to 5.00782, saving model to ./model\\04-5.0078.hdf5\n",
      "\n",
      "Epoch 5: val_loss improved from 5.00782 to 4.16245, saving model to ./model\\05-4.1624.hdf5\n",
      "\n",
      "Epoch 6: val_loss improved from 4.16245 to 3.66095, saving model to ./model\\06-3.6609.hdf5\n",
      "\n",
      "Epoch 7: val_loss improved from 3.66095 to 3.42110, saving model to ./model\\07-3.4211.hdf5\n",
      "\n",
      "Epoch 8: val_loss improved from 3.42110 to 3.00423, saving model to ./model\\08-3.0042.hdf5\n",
      "\n",
      "Epoch 9: val_loss improved from 3.00423 to 2.50109, saving model to ./model\\09-2.5011.hdf5\n",
      "\n",
      "Epoch 10: val_loss improved from 2.50109 to 2.20376, saving model to ./model\\10-2.2038.hdf5\n",
      "\n",
      "Epoch 11: val_loss improved from 2.20376 to 2.09216, saving model to ./model\\11-2.0922.hdf5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 13: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 14: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 15: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 16: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 17: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 18: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 19: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 20: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 21: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 22: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 23: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 24: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 25: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 26: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 27: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 28: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 29: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 30: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 31: val_loss did not improve from 2.09216\n",
      "\n",
      "Epoch 32: val_loss improved from 2.09216 to 2.06795, saving model to ./model\\32-2.0680.hdf5\n",
      "\n",
      "Epoch 33: val_loss improved from 2.06795 to 1.98579, saving model to ./model\\33-1.9858.hdf5\n",
      "\n",
      "Epoch 34: val_loss improved from 1.98579 to 1.92088, saving model to ./model\\34-1.9209.hdf5\n",
      "\n",
      "Epoch 35: val_loss improved from 1.92088 to 1.84897, saving model to ./model\\35-1.8490.hdf5\n",
      "\n",
      "Epoch 36: val_loss improved from 1.84897 to 1.75007, saving model to ./model\\36-1.7501.hdf5\n",
      "\n",
      "Epoch 37: val_loss improved from 1.75007 to 1.65995, saving model to ./model\\37-1.6600.hdf5\n",
      "\n",
      "Epoch 38: val_loss improved from 1.65995 to 1.50950, saving model to ./model\\38-1.5095.hdf5\n",
      "\n",
      "Epoch 39: val_loss improved from 1.50950 to 1.30139, saving model to ./model\\39-1.3014.hdf5\n",
      "\n",
      "Epoch 40: val_loss improved from 1.30139 to 1.14462, saving model to ./model\\40-1.1446.hdf5\n",
      "\n",
      "Epoch 41: val_loss improved from 1.14462 to 1.09109, saving model to ./model\\41-1.0911.hdf5\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.09109\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.09109\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.09109\n",
      "\n",
      "Epoch 45: val_loss improved from 1.09109 to 1.07441, saving model to ./model\\45-1.0744.hdf5\n",
      "\n",
      "Epoch 46: val_loss improved from 1.07441 to 1.02533, saving model to ./model\\46-1.0253.hdf5\n",
      "\n",
      "Epoch 47: val_loss improved from 1.02533 to 1.00054, saving model to ./model\\47-1.0005.hdf5\n",
      "\n",
      "Epoch 48: val_loss improved from 1.00054 to 0.99999, saving model to ./model\\48-1.0000.hdf5\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.99999\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.99999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x239320c8c70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# seed 값 설정\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 데이터 입력\n",
    "wine = load_wine()\n",
    "\n",
    "X = wine.data\n",
    "Y = tf.keras.utils.to_categorical(wine.target, num_classes=3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 13, activation = \"relu\"))\n",
    "model.add(Dense(13, activation = \"relu\"))\n",
    "model.add(Dense(8, activation = \"relu\"))\n",
    "model.add(Dense(3, activation = \"softmax\"))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "              optimizer = \"adam\",\n",
    "              metrics = [\"accuracy\"])\n",
    "\n",
    "# 모델 저장 폴더 만들기\n",
    "MODEL_DIR = \"./model/\"\n",
    "if not os.path.exists(MODEL_DIR) :\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "# 모델 업데이트 및 저장\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = \"val_loss\", verbose = 1, save_best_only = True)\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor = \"val_loss\", patience = 100)\n",
    "\n",
    "history = model.fit(X, Y, validation_split = 0.2, epochs = 3500, batch_size = 500,\n",
    "          verbose = 0, callbacks = [early_stopping_callback, checkpointer])\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
